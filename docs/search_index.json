[["introduktion.html", "NDAB02 Material 1 Introduktion 1.1 R och RStudio", " NDAB02 Material Isak Hietala 2021-04-26, ver 0.4 1 Introduktion Detta material ämnar att ge en introduktion till statistisk analys med hjälp av programvaran R för studenter som läser kursen NDAB02. 1.1 R och RStudio R är ett programmeringsspråk som används väldigt frekvent inom statistikområdet. Det gränssnitt som oftast används för att prata med språket är RStudio. I det nedre högra fönstret kan du välja att antingen navigera runt bland mapparna på datorn, titta på utskrivna diagram, hitta olika paket som kan installeras samt använda hjälpfunktionen. Det smidigaste sättet att få hjälp med en viss funktion är att skriva till exempel ?geom_bar och sedan trycka på Enter-tangenten i Console-fönstret, så kommer hjälpdokumentation till funktionen geom_bar() upp i nedre högra fönstret. I samma fönster kan du även definiera för RStudio i vilken mapp du har de filer som kommer användas. Notera att de filer du importerar samt de koder du sparar måste vara i denna mapp, samt att sökvägen till mappen inte får innehålla bokstäverna Å, Ä eller Ö. Bestäm sökvägen genom att att använda setwd(). Förslagsvis skapar du en ny mapp med lämpligt namn på din hemkatalog som du har dina filer i. För att öppna ett textdokument där du kan skriva kod som sedan sparas som en separat fil går du menyvägen File -&gt; New File -&gt; R Script. Du kan även öppna en ny flik i detta fönster där annan kod kan skrivas, genom att gå till samma menyväg igen. 1.1.1 Grundläggande programmering i R Det första som du bör göra när du startar en ny session i R, och har öppnat ett nytt R Script, är att ange en s.k. arbetsmapp. Detta är en mapp på datorn som innehåller de filer som du vill arbeta med under sessionen. Fördelen med att lägga alla filer i en och samma mapp och ange en arbetsmapp i R är att du undviker att ange långa sökvägar till filerna om du vill importera dessa till R. För att hitta sökvägen till mappen på din dator som du sparat ner alla dina filer, behöver du öppna upp mappen i ditt operativssystems filhanterare och följa någon av följande instruktioner instruktioner för Windows / instruktioner för Mac. Kopiera denna sökväg och använd sedan funktionen setwd() för att R ska riktas mot rätt mapp på datorn. Notera att alla \\ måste bytas ut med antingen \\\\ eller / för att R ska kunna läsa av sökvägen korrekt. ## Anger en arbetsmapp på datorn med alla filer som ska användas setwd(&quot;C:/Users/namn/mapp&quot;) R använder sig utav s.k. paket med redan skapade funktioner som du kan använda dig utav för att förenkla din programmering. För att dessa funktioner ska kunna användas i din session måste du säga till R att paketet ska laddas upp i sessionen. Du kan tänka det som att du vid din arbetsbänk plockar fram en verktygslåda innehållande de verktyg som du kommer vilja använda under ditt arbete. Om du inte har verktygslådan bredvid dig kommer det bli svårt att använda något av verktygen. Laddningen av paketen kan göras med antingen funktionen library() eller require(). Om du har en ny installation av R på datorn måste du först installera paketen på datorn (ladda ner alla filer som behövs från internet). Det är inte svårare än att använda funktionen install.packages() med paketets namn inuti \"\" enligt koden nedan. Detta behöver endast göras en gång för nya installationer av R! ## Om paketen inte finns på datorn måste de installeras. KÖRS ENDAST EN GÅNG! install.packages(&quot;ggplot2&quot;) install.packages(&quot;RColorBrewer&quot;) ## Laddar paketen innehållande de funktioner som vi vill använda require(ggplot2) require(RColorBrewer) Termen funktion har använts frekvent tidigare i texten och kan behöva förtydligas. En funktion är strukturerad på följande sätt: funktionens_namn(*argument* som styr vad funktionen gör, separerade med kommatecken) Argumentens värden anges med = till skillnad från vanlig kodning där &lt;- anges för att tilldela värden. En funktion börjar med en ( och slutar men en ). Detta betyder att man kan skriva en funktion på både en eller flera rader. Notera att R dock måste ha någon form utav indikation att funktionen fortsätter, t.ex. ett , för att ange att flera argument tillkommer eller ett + för att koppla ihop flera funktioner, likt som kommer presenteras nedan för ggplot2-paketet. För att lägga till värden i R som variabler för sedan kan användas för vidare analys kan nedan kod göras: ## Siffror anges bara som de är valfritt_nummer &lt;- 3 ## För att man ska ange text måste de omfattas av &quot; &quot; för att R ska läsa de som text valfri_text &lt;- &quot;Hello world!&quot; ## En vektor med värden A &lt;- c(3, 5, 3, 7) B &lt;- c(1, 3, 2, 4) ## En matris med värden A_2 &lt;- matrix(A, nrow = 2) ## Matematiska beräkningar kan sedan utföras med tidigare skapade variabler. C &lt;- A + B D &lt;- A * B procent &lt;- D / sum(D) * 100 ## En vektor med textstränger ord &lt;- c(&quot;Apelsin&quot;, &quot;Banan&quot;, &quot;Citron&quot;) 1.1.2 Ladda in material För att kunna arbeta med datamaterial som du samlat in från någon annanstans används någon av read.xx()-funktionerna. Det vanligaste sättet att göra det är genom att skapa en kommaseparerad fil via exempelvis Excel och sedan importera den till R via read.csv2(). Se till att kolumn- och decimalseparatorn anges enligt det format som filen har med sep =, och dec =. Ett tips är att öppna .csv-filen i Notepad++ eller annan enkel ordbehandlare för att se vilka symboler som används. ## Laddar in datamaterial bil &lt;- read.csv2(&quot;data_om_bilar.csv&quot;, dec = &quot;.&quot;) elev &lt;- read.csv2(&quot;data_om_elever.csv&quot;, dec = &quot;.&quot;) "],["visualisering.html", "2 Visualisering 2.1 Varför är visualisering viktigt? 2.2 Grundläggande begrepp 2.3 Ett bra diagram 2.4 Visualisering av beskrivande statistik 2.5 Samband mellan variabler", " 2 Visualisering 2.1 Varför är visualisering viktigt? En bild säger mer än tusen ord är ett vanligt förekommande ordspråk som innehåller mycket sanning. Speciellt när det kommer till information används visualiseringar i olika former för att på ett effektivt och tydligt sätt förmedla stora mängder data som hade varit svårare att uppfatta som enskilda siffror. Visualisering ger en statistiker möjlighet att lära känna sitt datamaterial innan mer djupgående analys påbörjas. Med mycket data är det oftast svårt få grepp om sina variabler och observationer. Frågor som; vad är sambandet mellan mina variabler? eller finns det några felaktigheter i materialet? blir mycket enklare att besvara med hjälp av visualiseringar. Om du ska presentera något banbrytande för dina kollegor eller chefer måste du på något sätt kunna sammanfatta resultatet på ett lättförståeligt och tydligt sätt. Visualiseringar är ett verktyg som ger många möjligheter att komprimera informationen som ska förmedlas. 2.2 Grundläggande begrepp Ett diagram innehåller olika delar som kommer refereras i resterande text. Här följer en kortare ordlista: Diagramyta: Det område som innehåller all information tillhörande en visualisering Rityta: Det område som innehåller det faktiska data som visualiseras Axel: Kanterna som begränsar ritytan, ofta benämnt som x- och y-axel för den vågräta ( - ) respektive lodräta ( | ) axeln Axelförklaring: En rubrik som beskriver vad den angivna axeln visar för information Skalvärden: Steg som anger specifika värden på den angivna axeln Stödlinjer: Linjer vilka agerar som en förlängning av axlarnas skalvärden i bakgrunden av ritytan Titel/rubrik: En rubrik för diagrammet Källhänvisning: En text placerade i någon av de nedre hörnen som anger en källa för det visualiserade datamaterialet om sådan finns 2.3 Ett bra diagram För att skapa ett bra diagram behöver man tänka på några olika saker. Vilken typ av variabel som ska visualiseras påverkar huruvida ett diagram är tydligt eller inte. Samma sorts diagram kan mycket enkelt och tydligt visualisera en kvalitativ variabel men visualiserar kvantitativa variabler värdelöst Figur 2.1: Exempel på stapeldiagram för en kvalitativ (t.vä.) och kvantitativ (t.hö.) variabel Ritytan innehåller den information som ska förmedlas och bör därför få ta upp majoriteten av platsen i ett diagram. Om man anger för stora rubriker blir det lätt att man inkräktar på ritytan. Detsamma gäller om y-axeln innehåller långa skalvärdesnamn. Figur 2.2: Exempel på diagram med majoriteten rityta (t.vä.) och för liten rityta (t.hö.) Stödlinjer bör finnas för att underlätta utläsningen av information långt från respektive axel. Dessa bör dock inte ta över diagrammet utan enbart finnas i bakgrunden. Notera att stödlinjer kan komma att justera beroende på vilket sammanhang diagrammen används till. Beroende på upplösning, ljusstyrka eller andra skärmegenskaper kan ibland ljusa och smala linjer försvinna in i den vita bakgrunden. Då är tjockare och starkare stödlinjer befogat. Figur 2.3: Exempel på stödlinjer som ligger i bakgrunden (t.vä.) och stödlinjer som stjäl fokus från informationen (t.hö.) Ett bra diagram har också läsbar text oavsett storleken på diagrammet. En bra referens kan vara att förhålla den minsta texten i diagrammet till ungefär samma storlek som brödtexten i rapporten eller presentationen. Försök att alltid tänka på att underlätta för läsaren! Figur 2.4: Exempel på läsbar text (t.vä.) och på gränsen till för liten text (t.hö.) Källhänvisning bör finnas i alla diagram där informationen är hämtat från någon annan källa än oss själva. Figur 2.5: Exempeldiagram med källhänvisning 2.4 Visualisering av beskrivande statistik 2.4.1 Stapeldiagram Den absolut enklaste formen av visualisering är stapeldiagram. Denna diagramtyp består utav staplar vars höjd kommer från ett värde i datamaterialet, vanligtvis då man har en kvalitativ variabel och dess frekvenser (antalet av de olika arterna i diagrammen från tidigare kapitel), men diagramtypen kan också användas då man har en kvantitativ variabel uppdelad på en eller flera kvalitativa variabler (medellönen uppdelat på olika sektorer). Följande exempel kommer utgå från det första fallet. Olika programvaror kräver olika mycket bearbetning av datamaterialet innan diagrammet kan skapas. Vissa kräver att du själv skapar en frekvenstabell och anger att höjden av respektive stapel ska bestämmas av den tillhörande frekvensen, medan andra kan göra dessa beräkningar direkt på rådata. Som tidigare nämnt om R använder sig programmet av diverse paket som innehåller redan skapade funktioner för att lösa diverse arbetsuppgifter. För visualisering kommer vi använda oss främst av paketet ggplot2 som bygger på vad som kallas för grammar of graphics. (@ggplot2019) Detta är ett försök till att formalisera ett språk för hur man enhetligt bör skriva visualiseringar och även SPSS använder sig av grunderna till detta språk. Det första steget för att få ta del av funktionerna är att ladda paketet till din R-session genom: require(ggplot2) Paketets visualiseringar utgår ifrån en data.frame vilket innebär att vi behöver ladda in ett datamaterial innan vi kan påbörja visualiseringarna. Detta kan göras med någon utav funktionerna read.csv(), read.csv2() osv. Se till att datamaterialet som laddats in ser ut som vi förväntar att det ska göra, exempelvis är decimaler korrekt angivna, har vi lika många variabler i R som i Excel och liknande. Med koden nedan kan datamaterialet som används som exempel genom hela denna text laddas in i R till objektet som kallas exempeldata. Vi kan även se hur materialet ser ut genom att använda head() som skriver ut ett antal observationer. Materialet ser ut att innehålla fem variabler, varav två är kvalitativa. exempeldata &lt;- read.csv2(file = &quot;732G45_exempeldata.csv&quot;) head(exempeldata, n = 5) ## civilstand alder bil syskon lon ## 1 Par 26 Opel 0 26793 ## 2 Par 44 Ford 2 49588 ## 3 Par 34 Volvo 3 40461 ## 4 Par 33 Ingen 4 40299 ## 5 Par 32 Audi 3 36942 2.4.1.1 Grundkomponenter Vi kan nu börja med att skapa stapeldiagrammet. Vi börjar med de tre grundkomponenterna av ett ggplot-diagram; ggplot(), aes() och geom(). Alla diagram måste innehålla dessa tre komponenter i någon form för att vi ska kunna producera något överhuvudtaget, sen kan vi lägga till andra instruktioner för att ändra diagrammet utseende. I ggplot() anges vilket datamaterial vi vill använda för visualiseringen: ggplot(exempeldata) Som vi ser skapas inget utifrån detta kommando, vi har bara sagt åt R att använda datamaterialet men inte vad den ska göra med det. Nästa steg är att ange vilka variabler vi vill använda för axlarna i diagrammet. När det kommer till stapeldiagram finns två olika sätt att göra; antingen har vi rådata och låter R räkna ut frekvensen av de olika kategorierna själv eller så skapar vi en egen frekvenstabell och anger y = frekvens. Vi kommer först börja med exemplet utifrån rådata: ggplot(exempeldata) + aes(x = bil) Nu ser vi att R ritat ut de olika bilarna som finns i materialet på x-axeln, men vi har fortfarande inte sagt åt R vad vi vill att den ska göra med informationen vi ska visualisera. Den sista grundkomponenten är den som styr vilken diagramtyp vi skapar och i ggplot2 finns många olika som vi kommer stöta på i denna text. För ett stapeldiagram anger vi geom_bar() från engelska termen bar chart. ggplot(exempeldata) + aes(x = bil) + geom_bar() För att y-axeln ska visa relativa frekvenser istället för absoluta, kan vi i geom_bar() lägga till koden aes(y = stat(count/sum(count))). Diagrammet ändrar sig inte i sin form, staplarna är fortfarande lika höga i relation till varandra, men tolkningar av detta diagram kan nu göras i andelar (procent) istället för antal. ggplot(exempeldata) + aes(x = bil) + geom_bar(aes(y = stat(count/sum(count)))) Med dessa grundkomponenter får vi fram ett diagram, men vi kan väl alla hålla med om att det i detta läge inte ser särskilt snyggt och tydligt ut. Ett snabbt och enkelt sätt att få till lite snyggare diagram är att använda någon utav ggplots teman som finns tillgängliga genom olika theme(). Exempelvis är ett stilrent tema att utgå ifrån theme_bw() likt: ggplot(exempeldata) + aes(x = bil) + geom_bar(aes(y = stat(count/sum(count)))) + theme_bw() Det är nu den största funktionaliteten med ggplot2 kommer in. Vi kan spara instruktionerna vi gett åt R för att skapa diagrammet och senare lägga till fler instruktioner med andra funktioner genom att använda + på samma sätt som koderna ovan är skrivna. Vi sparar därför de nuvarande instruktionerna i ett objekt som vi kallar för p (vi kan döpa denna till vad som helst) likt: p &lt;- ggplot(exempeldata) + aes(x = bil) + geom_bar(aes(y = stat(count/sum(count)))) + theme_bw() Nu ligger alla instruktioner för hur R ska rita upp diagrammet sparat i p men för att R också ska producera diagrammet måste vi också säga det likt: p Vi kan nu lägga till ytterligare funktioner exempelvis: p + coord_flip() eller: p + scale_y_continuous(labels = scales::percent) Notera att diagrammet inte roterades i det andra diagrammet när vi ändrade hur skalvärdena på y-axeln ser ut. Detta är för att vi endast sagt åt R att rita diagrammet med vardera tillagda instruktion vid två olika tillfällen utan att ha sparat de någonstans. För att R ska spara dessa instruktioner tillsammans med grundkomponenterna vi angivit innan måste vi spara ovanstående kod till ett objekt: p &lt;- p + scale_y_continuous(labels = scales::percent) p 2.4.1.1.1 Sammanställd data Om vi istället för rådata har sammanställd data exempelvis i form utav en frekvenstabell kan vi ändå skapa samma ovanstående diagram. Vi tänker oss att data om bilarna istället för de 64 observationerna är presenterad i följande tabell: Tabell 2.1: Fördelning av bilmärken i urvalet Märke Frekvens Audi 11 Ford 9 Ingen 5 Nissan 10 Opel 4 Toyota 5 Volkswagen 6 Volvo 14 Det som är viktigt är att vi fortfarande i R hanterar denna frekvenstabell som en data.frame, då ggplot kräver formatet för sina visualiseringar. Datamaterialet ser då istället ut som: head(exempeltabell) ## Märke Frekvens ## 1 Audi 11 ## 2 Ford 9 ## 3 Ingen 5 ## 4 Nissan 10 ## 5 Opel 4 ## 6 Toyota 5 För att skapa diagrammet som vi sett tidigare måste vi lägga till några argument i aes() och geom_bar() likt koden nedan. Argumentet stat = \"identity\" i geom_bar() krävs för att R ska räkna värdet på den angivna y-variabeln som höjden på stapeln. ggplot(exempeltabell) + aes(x = Märke, y = Frekvens) + geom_bar(stat = &quot;identity&quot;) + theme_bw() 2.4.1.2 Färger Om vi vill ändra färgen på olika delar av diagrammet exempelvis staplarna kan vi göra detta inuti geom_bar() med argumenten color för kantlinjerna och fill för fyllnadsfärgen. För att se vilka färger som går att ange kan man köra funktionen colors() för deras namn eller hämta hem följande PDF som har färgerna utskrivna. Vi kommer senare titta närmare på färger och dess funktion i visualiseringar. p &lt;- ggplot(exempeldata) + aes(x = bil) + geom_bar(fill = &quot;dark orange&quot;, color = &quot;black&quot;, aes(y = stat(count/sum(count)))) + theme_bw() p 2.4.1.3 Stödlinjer Nu vill vi ändra lite stödlinjer så att de syns och hjälper till att förtydliga informationen vi vill visa. När det kommer till stapeldiagram behövs inte stödlinjer på x-axeln då staplarna sträcker sig hela vägen ner till dess skalvärden. Däremot behöver vi förtydliga skalvärdena på y-axeln. För att ändra utseendet på olika delar i ett diagram används theme() och diverse olika argument däri. Titta i dokumentationen för funktionen för att få en inblick i vad som kan ändras i diagrammet. Oftast ska dessa delar anges med en utav element-funktioner, beroende på typen som ska ändras. Text ändras med element_text(), linjer med element_line() och delar kan helt och hållet tas bort genom element_blank(). Nedanstående kod ändrar stödlinjerna på y-axelns färg till lite mörkare grå än standardvärdet (panel.grid.major för stödlinjerna som följer skalvärdena, panel.grid.minor för stödlinjer emellan skalvärdena) och tar bort stödlinjerna från x-axeln. p &lt;- p + theme(panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), panel.grid.major.y = element_line(color = &quot;gray70&quot;), panel.grid.minor.y = element_line(color = &quot;gray80&quot;)) p 2.4.1.4 Text Det som saknas just nu i diagrammet är tydligare (och större) text som förklarar de olika delarna av diagrammet för läsaren. De olika etiketterna kan alla anges i samma funktion genom olika argument likt: p &lt;- p + labs(x = &quot;Bilmärke&quot;, y = &quot;Andel&quot;, caption = &quot;Källa: Hietala (2019)&quot;) p Det vi kan förhålla oss till när vi anger titeln för y-axeln är att den beskriver enheten som används för att mäta axelns skalvärden. Då vi i detta fall har värden mellan \\(0\\) och \\(1\\) bör vi ange Andel som titel. Om vi skulle haft absoulta frekvenser skulle en lämplig titel varit Antal. Om vi istället för andelar anger skalan i procent likt tidigare diagram kan det diskuteras huruvida det behövs en y-axeltitel eftersom enheten redan är angiven på skalan. Diagrammet skulle då kunna se ut som: p + scale_y_continuous(labels = scales::percent) + labs(y = &quot;&quot;) Vi kan även ändra andra aspekter av textens utseende i diagrammet, exempelvis hur stor den är, dess rotation eller position. Detta görs med olika argument i theme(). Vi kan ändra utseendet på axeltexter med axis.title, skalvärden med axis.text och källhänvisningen med plot.caption. Alla dessa delar kräver instruktioner från element_text()-funktionen och där kan argument som: angle styra rotationen, hjust och vjust styra placeringen horisontellt respektive vertikalt, size styra textstorleken, font styra typsnittet, face ange en eventuell fet- eller kursivmarkering av texten p &lt;- p + theme(plot.caption = element_text(face = &quot;italic&quot;), axis.title.y = element_text(angle = 0, vjust = 0.5, size = 11), axis.title.x = element_text(size = 11), axis.text = element_text(size = 10, color = &quot;black&quot;)) p 2.4.1.5 Skalvärden Ibland kan de automatiskt genererade axelskalorna medföra svårigheter att utläsa informationen som vi ska presentera. Därför är det sista vi kommer titta på funktioner för att ändra dessa skalor. Vilken funktion vi vill använda och hur man kan ändra utseendet påverkas av vilken sorts variabel som anges på den specifika axeln. Exempelvis kanske vi vill i diagrammet ändra så att den kontinuerliga y-axeln endast visar skalvärden var 10:e procent istället för var 5:e som nu sker. Detta gör vi då via: p + scale_y_continuous(breaks = seq(from = 0, to = 1, by = .10)) Argumentet breaks = seq(from = 0, to = 1, by = .10) anger att vi vill att värden (breaks) ska visas på specifika ställen på axeln. seq()-funktionen är ett snabbare sätt att skapa en vektor med lika steglängd mellan värden som vi använder för att skapa c(0, 0.1, 0.2, 0.3, ..., 1). Notera att trots att vi anger värden som går hela vägen upp till 1, kommer inte diagrammet visa detta. Om vi skulle vilja visa en större del av axeln kan vi ange skalans gränser med limits likt koden nedan. Risken med detta är att vi skapar för mycket onödig tom rityta som minskar utrymmet för den information som vi vill presentera. p + scale_y_continuous(breaks = seq(from = 0, to = 1, by = .10), limits = c(0, 0.35)) Något som dock är snyggt att göra med specifikt stapeldiagram är att ta bort den lilla yta som finns under alla staplar och låta y-axeln möta x-axeln vid y = 0. Detta kan vi göra med argumentet expand = c(0,0), men då måste vi ange gränserna på skalan. p &lt;- p + scale_y_continuous(breaks = seq(from = 0, to = 1, by = .10), limits = c(0, 0.25), expand = c(0,0)) p 2.4.2 Grupperat stapeldiagram Om vi har ett datamaterial bestående av flera kvalitativa variabler kan vi ibland vilja visualisera fördelningen av en variabel grupperat på en annan, exempelvis Hur ser fördelningen av bilmärken ut, uppdelat på civilstånd?. Det kanske finns några intressanta relationer mellan dessa två variabler som vi skulle vilja undersöka vidare, men som tidigare sagt är visualisering alltid det första steget för att lära känna sitt datamaterial. I vårt exempeldata har vi två kvalitativa variabler, civilstand och bil. För att visualisera ett grupperat stapeldiagram behöver vi välja en grupperings- och en fördelningsvariabel. Fördelninsgsvariabeln kommer grupperas över varje enskilda kategori från grupperingsvariabeln. I R måste vi ange grupperingsvariabeln likt det vi gjort tidigare som x och fördelningsvariabeln som fill inuti aes(). Detta kommer säga åt R att vardera värde på bil ska ha olika fyllnadsfärger. position = \"dodge\" bestämmer att staplarna ska ligga bredvid varandra och position = \"stack\" staplar de ovanpå varandra för ett s.k. stackat stapeldiagram. p &lt;- ggplot(exempeldata) + aes(x = civilstand, fill = bil) + geom_bar(position = &quot;dodge&quot;) + theme_bw() p För relativa frekvenser i ett grupperat stapeldiagram kan vi summera de visualiserade staplarna på två olika sätt. Antingen visar vi relativa frekvenser utifrån hela datamaterialet. Detta diagram kommer se exakt likadan ut som den med absoluta frekvenser men med andelar istället för antal. Vi använder samma kod som för det enkla stapeldiagrammet: aes(y = stat(count/sum(count))). ggplot(exempeldata) + aes(x = civilstand, fill = bil) + geom_bar(aes(y = stat(count/sum(count))), position = &quot;dodge&quot;) + theme_bw() Alternativet är att visa den relativa fördelningen grupperat på grupperingsvariabeln, alltså att vardera kategoris staplar summerar var för sig till 100 procent. Vi behöver då revidera koden som anger beräkningen till relativa frekvenser till: aes(y = stat(count/tapply(count, x, sum)[x])). ggplot(exempeldata) + aes(x = civilstand, fill = bil) + geom_bar(aes(y = stat(count/tapply(count, x, sum)[x])), position = &quot;dodge&quot;) + theme_bw() Figur 2.6: Grupperat stapeldiagram med enkel summering (t.vä.) och gruppvis summering (t.hö.) till 100 procent Tolkningarna på vardera av dessa diagram skiljer sig åt och valet styrs av vilken sorts frågeställning som vi vill besvara med visualiseringen. En jämförelse av gruppernas fördelning skulle bli tydlig med en gruppvis summering, medan presentation av fördelningen i materialet kan visualiseras med den enkla summeringen. 2.4.2.1 Förtydliga diagrammet Oavsett vilket sätt att summera staplarna som används ser de inte alls tydliga ut. Vi förtydligar till diagrammet med liknande hjälpfunktioner som tidigare stapeldiagram. Vi lägger till tydligare kantlinjer på staplarna, lägger till stödlinjer och etiketter, samt justerar utseendet på diverse texter samt ändrar skalan för y-axeln. p &lt;- ggplot(exempeldata) + aes(x = civilstand, fill = bil) + geom_bar(aes(y = stat(count/sum(count))), position = &quot;dodge&quot;, color = &quot;black&quot;) + theme_bw() + theme(panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), panel.grid.major.y = element_line(color = &quot;gray70&quot;), panel.grid.minor.y = element_line(color = &quot;gray80&quot;), plot.caption = element_text(face = &quot;italic&quot;), axis.title.y = element_text(angle = 0, vjust = 0.5, size = 11), axis.title.x = element_text(size = 11), axis.text = element_text(size = 10, color = &quot;black&quot;)) + labs(x = &quot;Civilstånd&quot;, y = &quot;Andel&quot;, caption = &quot;Källa: Hietala (2019)&quot;) + scale_y_continuous(expand = c(0,0), breaks = seq(0, 0.20, by = 0.05), limits = c(0, 0.16)) p 2.4.2.2 Färger Det som också urskiljer ett grupperat stapeldiagram med det skapades tidigare är att vi nu har en legend till höger av diagramytan som innehåller ytterligare information som krävs för att läsa av diagrammet. Vi har fått olika färger på den valda fördelningsvariabeln som kopplas samman till de olika kategorierna. Dessa vill vi nu ändra tillsammans med att ändra lite information i legenden för att göra den tydligare. För att skapa ett diagram som har en enhetlig och tydlig färgpalett kommer paketet RColorBrewer till användning. Ladda paketet med require(RColorBrewer) och titta på de olika färgkategorierna som finns att använda genom display.brewer.all(). Det rekommenderas att välja någon av de monokromatiska färgskalorna likt \"Oranges\" eller \"Purples\". För att revidera utseendet på legenden och de använda färgerna används funktionen scale_X_manual() där X ersätts med den sorts gruppering som har gjorts för att skapa legenden, i detta fall fill. I values anges vilka färger som ska användas i diagrammet och där vill vi då använda någon palett från RColorBrewer genom brewer.pal()-funktionen. Argumentet n anger hur många färger vi vill ha och name anger vilker palett vi vill ta färgerna från. p &lt;- p + scale_fill_manual(name = &quot;Bilmärke&quot;, values = brewer.pal(n = 8, name = &quot;Oranges&quot;)) p 2.4.3 Histogram Om variabeln istället är kvantitativ och vi vill presentera fördelningen av denna variabel, är histogram (eller lådagram) lämpligt att använda. Likt tidigare diagram i R behöver vi först ange vilket datamaterial samt vilken variabel som vi ska visualisera. p &lt;- ggplot(exempeldata) + aes(alder) När väl det är gjort måste vi på samma sätt som tidigare ange vilken form av visualisering som ska göras. För histogram använder vi geom_histogram(), med argumentet bin som styr hur många klassintervall vi vill ha. Om vi istället vill ange hur breda intervallen ska vara kan vi använda argumentet binwidth. p &lt;- p + geom_histogram(fill = &quot;orange&quot;, color = &quot;black&quot;, bins = 10) p Vi kan också snygga till diagrammet med alla funktioner som vi tidigare använt för stapeldiagram. p &lt;- p + scale_y_continuous(expand = c(0,0), limits = c(0, 20)) + theme_bw() + theme(axis.title.y = element_text(angle = 0, hjust = 1, vjust = 0.5), plot.title = element_text(hjust = 0.5), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), panel.grid.major.y = element_line(color = &quot;dark gray&quot;)) + labs(y = &quot;Antal&quot;, x = &quot;Ålder&quot;, title = &quot;Fördelning av ålder&quot;, caption = &quot;Källa: Hietala (2019)&quot;) p 2.4.4 Lådagram Ett alternativ att presentera fördelningen för en kvantitativ variabel är lådagram. Denna visualiseringstyp lämpar sig bättre om det finns extremvärden i materialet då diagrammet utgår ifrån kvartiler. Vi börjar strukturera ett lådagram på samma sätt som vi gjorde med histogrammet, dock behöver vi använda ett knep för att R ska skapa ett snyggt diagram. I aes() måste x = factor(0) som är ett sätt för R att skapa en tom kategorisk variabel. Lådagrammet skapas med geom_boxplot(). För att ta bort onödiga skalvärden och axelförklaring för den tomma variabeln som vi skapat används värdet NULL på de argument som vi vill ta bort, exempelvis breaks i scale_x_discrete(). p &lt;- ggplot(exempeldata) + aes(x = factor(0), y = alder) + geom_boxplot(fill = &quot;orange&quot;) + scale_x_discrete(breaks = NULL) p Snyggar till diagrammet som tidigare. p &lt;- p + theme_bw() + theme(axis.title.y = element_text(angle = 0, hjust = 1, vjust = 0.5), plot.title = element_text(hjust = 0.5), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), panel.grid.major.y = element_line(color = &quot;dark gray&quot;)) + labs(y = &quot;Ålder&quot;, x = NULL, title = &quot;Fördelning av ålder&quot;, caption = &quot;Källa: Hietala (2019)&quot;) p 2.5 Samband mellan variabler 2.5.1 Spridningsdiagram När ett datamaterial innehåller flera variabler kan det vara intressant att undersöka vilka (om några) variabler har ett samband med varandra. Detta kan göras på olika sätt, men visualisering i ett spridningsdiagram är ett sätt som möjliggör att se många olika typer av samband mellan två variabler. Vi utgår ifrån tidigare datamaterial och fokuserar på de två kvantitativa variablerna alder och lon i aes(). Här bör vi välja variabler till de olika axlarna som medför en logisk tolkning av vilken variabel som förklarar den andra. Den förklarande variabeln, x, anser vi förklara responsvariabeln, y, och med dessa variabler är det mer logiskt att alder förklarar lon för en individ. För att skapa ett spridningsdiagram används geom_point(). Argument som kan vara av intresse i denna funktion är color, shape eller size. p &lt;- ggplot(exempeldata) + aes(x = alder, y = lon) + geom_point() p Som vanligt lägger vi till lite extra kod för att ändra utseendet av diagrammet. När det kommer till stödlinjer och spridningsdiagram är syftet med diagrammet att se helheten, det generella sambandet mellan variablerna, mer än specifika värden för enstaka observationer. Detta betyder att stödlinjerna riskerar att ta för mycket fokus från diagrammet istället för att tillföra tydlighet. En lösning på detta är att försvaga styrkan på linjerna eller helt ta bort dem. p &lt;- p + theme_bw() + theme(axis.title.y = element_text(angle = 0, hjust = 1, vjust = 0.5), plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5), panel.grid.major.x = element_line(color = &quot;gray&quot;), panel.grid.minor.x = element_line(color = &quot;light gray&quot;), panel.grid.major.y = element_line(color = &quot;gray&quot;), panel.grid.minor.y = element_line(color = &quot;light gray&quot;)) + labs(title = &quot;Sambandet mellan ålder och lön&quot;, x = &quot;Ålder&quot;, y = &quot;Lön&quot;, caption = &quot;Källa: Hietala (2019)&quot;) p Då vi pratar om samband är det naturligt att gå vidare till en statistisk metod som kallas för regression som mer i detalj beskriver sambandet mellan variabler. Vi kommer inte gå igenom det så mycket i denna kurs men vi kan fortfarande visualisera den skattade regressionslinje som fås med hjälp av en metod som kallas minsta kvadrat skattning. I R lägger vi till ett till geom-objekt till samma diagram. method = lm anger att vi vill skatta en linjär modell (linear model) och se = FALSE anger att vi inte vill visa s.k. konfidensband. p + geom_smooth(method = lm, se = FALSE) ## `geom_smooth()` using formula &#39;y ~ x&#39; 2.5.1.1 Visualisering av olika datamaterial i samma diagram Om extremvärden skulle finnas i datamaterialet kommer sambandet (och en inritad regressionslinje) riskera att förskjuta det generella samband som finns. Observera att det i praktiken inte är så lätt att bara plocka bort extremvärden från datamaterialet utan en djupare dykning i orsakerna till detta värde. Är extremvärden en felinmatning eller är det ett riktigt värde som är en del av målpopulationen? För att visa hur vi kan använda olika datamaterial i samma diagram kommer vi göra det naïva och plocka bort dessa. I detta skede av er utbildning rekommenderas att ni identifierar dessa punkter i diagrammet och manuellt tar bort dessa ur data i Excel, sparar en ny fil med nytt namn, och importerar detta nya material till R och sparar det som ett nytt objekt. Det första vi måste göra för att diagrammet ska bli tydligt är att skapa en grupp (och tillhörande legendrad) för vardera regressionslinje. Detta görs genom att använda aes(color = \"gruppnamn\") inuti geom_smooth(). Vi ser nu att en legend lagts till i diagrammet med det angivna namnet på linjen som vi skrivit. p &lt;- p + geom_smooth(aes(color = &quot;med_extrem&quot;), method = lm, se = FALSE) p ## `geom_smooth()` using formula &#39;y ~ x&#39; För att lägga till den nya regressionslinjen utan extremvärden anges i geom_smooth() ett nytt data-objekt. Linjen kommer då ritas med samma variabler som angivits innan men utgå från detta materials värden, som saknar de extremvärden som man kan urskilja i materialet. p &lt;- p + geom_smooth(data = exempeldata_extrem, aes(color = &quot;utan_extrem&quot;), method = lm, se = FALSE) p ## `geom_smooth()` using formula &#39;y ~ x&#39; ## `geom_smooth()` using formula &#39;y ~ x&#39; Legenden kan behöva förtydligas lite och här får vi återigen användning av de gruppnamn som angetts tidigare i koden. Argumentet name ger en bättre titel på legenden och i values kan vi i vektorn säga specifikt vilka grupper som vi vill ha vissa färger likt \"gruppnamn\" = \"färg\". Vi vill också ange bättre etiketter på dessa grupper och detta görs med labels-argumentet. p &lt;- p + scale_color_manual(name = &quot;Datamaterial&quot;, values = c(&quot;med_extrem&quot; = &quot;black&quot;, &quot;utan_extrem&quot; = &quot;orange&quot;), labels = c(&quot;med_extrem&quot; = &quot;Hela materialet&quot;, &quot;utan_extrem&quot; = &quot;Utan extremvärden&quot;)) p ## `geom_smooth()` using formula &#39;y ~ x&#39; ## `geom_smooth()` using formula &#39;y ~ x&#39; 2.5.1.2 Extra visualisering Det kanske också kan vara intressant att peka ut vilka observationer som plockas bort vilket kan göras genom att skapa ytterligare ett datamaterial med enbart de valda extremvärdena. Vi kan då lägga till ett till geom_point() till diagrammet där vi ändrar shape till någon annan symbol som tydliggör att dessa har plockats bort. p + geom_point(data = exempeldata_extrem_points, shape = &quot;x&quot;, size = 4) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## `geom_smooth()` using formula &#39;y ~ x&#39; 2.5.2 Linjediagram För att vi ska kunna skapa ett linjediagram över flera serier behöver vi importera data med grupperingskolumner. Även om vi enbart ska visualisera en serie är det bra att få in rutinen att representera data i R på detta sätt. Datamaterialet bör alltså se ut som följer: Tabell 2.2: Första observationerna i datamaterialet med en grupperingsvariabel Region År Region Antal 1975 Hela landet 331 1976 Hela landet 332 1977 Hela landet 371 1978 Hela landet 364 1979 Hela landet 364 När materialet nu innehåller tre variabler (en som visar tid, en som visar vilken grupp värden och år tillhör, samt mätvärdet för den angivna gruppen och året) kan vi påbörja visualiseringen. Exempeldata innehåller information om antalet anmälda våldsbrott per 100 000 invånare i hela landet, Västernorrland och Östergötland och är hämtat från SCB. 2.5.2.1 En tidsserie Om endast en serie ska visualiseras kan vi plocka ut en grupp från det tidigare materialet och visualisera endast det. Vi gör detta med filter() från dplyr-paketet. Kodexemplet gör denna filtrering inuti ggplot() men vi skulle lika gärna skapa ett filtrerad data som sparas som ett nytt objekt och använda det senare i ggplot(). ## Anger att vi endast vill ha en del av data i diagrammet p &lt;- ggplot( filter(.data = tidsserie_exempel, Region == &quot;Hela landet&quot;) ) När vi nu sagt att endast en del av materialet ska visualiseras kan vi som tidigare ange aes() där vi nu måste ange både x och y. På x-axeln vill vi ha tiden, alltså År i vårt exempelmaterial, och y-axeln ska innehålla mätvärden, i detta fall variabeln Antal. För att skapa ett linjediagram används geom_line(). I den funktionen finns argument såsom color, linetype, size och liknande som kan användas för att ändra utseendet av diagrammet. Ibland kan linjen bli väldigt smal och svår att se men då kommer argumentet size väl till pass. p &lt;- p + aes(x = År, y = Antal) + geom_line(color = &quot;dark orange&quot;, size = 1) p Som tidigare ändrar vi det visuella och lägger till ytterligare förtydligande texter med liknande koder som innan. Till linjediagram vill vi ofta kunna se både lod- och vågräta avstånd vilket innebär att stödlinjer bör finnas åt båda hållen. Det kan dock vara av intresse att använda och ändra på panel.grid.minor-linjerna till en svagare färg för att göra skillnad på de olika stödlinjerna. I exemplet nedan används en mörkare grå färg för panel.grid.major. Något som också introducerats i nedanstående kod är plot.subtitle i theme() som styr egenskaper av undertiteln som i detta diagram kan vara bra för att förtydliga vilken region som materialet visar. Undertitelns text läggs till i labs() och subtitle-argumentet. p &lt;- p + theme_bw() + theme(axis.title.y = element_text(angle = 0, hjust = 1, vjust = 0.5), plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5), panel.grid.major.x = element_line(color = &quot;dark gray&quot;), panel.grid.minor.x = element_line(color = &quot;gray&quot;), panel.grid.major.y = element_line(color = &quot;dark gray&quot;), panel.grid.minor.y = element_line(color = &quot;gray&quot;)) + labs(y = &quot;Antal&quot;, x = &quot;År&quot;, title = &quot;Antal anmälda våldsbrott per 100 000 invånare&quot;, subtitle = &quot;Hela landet&quot;, caption = &quot;Källa: SCB (2012)&quot;) p 2.5.2.2 Flera tidsserier För att visualisera flera tidsserier i ett diagram kräver ggplot2 att datamaterialet ska vara formaterad med en grupperingsvariabel. För att R ska göra skillnad på dessa olika grupper måste group och/eller color argumentet i aes innehålla den grupperingsvariabel som finns i data. p &lt;- ggplot(tidsserie_exempel) + aes(x = År, y = Antal, color = Region, group = Region) + geom_line(size = 1) p Som tidigare kan vi nu ändra om flera aspekter av diagrammet men nu måste vi också ändra den legend som skapas från grupperna i aes(). När vi nu vill ändra linjefärger är det funktionen scale_color_manual() som ska användas, specifikt argumentet values. Problemet som vi kommer märka är att det är svårt att skapa en vektor med färger som är tydliga nog för olika situationer. Kodexemplet nedan försöker använda delar av brewer.pal(palette = \"Oranges\") tillsammans med en svart grundfärg för att bibehålla en färgstil. brewer.pal()-funktionen försöker plocka färger från den angivna paletten som skiljer sig från varandra men att ange n = 3 för de tre regionerna ger en alltför ljus färg som den första. Indexeringen [-1] plockar bort den första ljusa färgen och vi lägger istället till svart först i values-vektorn. p &lt;- p + scale_color_manual(values = c(&quot;black&quot;, brewer.pal(n = 3, &quot;Oranges&quot;)[-1])) + theme_bw() + theme(axis.title.y = element_text(angle = 0, hjust = 1, vjust = 0.5), plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5), panel.grid.major.x = element_line(color = &quot;dark gray&quot;), panel.grid.minor.x = element_line(color = &quot;gray&quot;), panel.grid.major.y = element_line(color = &quot;dark gray&quot;), panel.grid.minor.y = element_line(color = &quot;gray&quot;)) + labs(y = &quot;Antal&quot;, x = &quot;År&quot;, title = &quot;Antal anmälda våldsbrott per 100 000 invånare&quot;, subtitle = &quot;Jämförelse av riket och två län&quot;, caption = &quot;Källa: SCB (2012)&quot;) p 2.5.3 Punktdiagramsmatris För att skapa en punktdiagramsmatris (spridningsdiagramsmatris) i R behöver vi använda ytterligare ett paket, nämligen GGally. I detta paket finns funktionen ggpairs() som är (av författarna) skapat som som en samling ggplot2-instruktioner som möjliggör skapandet av flera spridningsdiagram inuti ett och samma diagram. Kom ihåg att ladda in detta nya paket i R innan vi fortsätter. require(GGally) Datamaterialet som används till detta exempel är ett utav de inbyggda materialen som finns i R, nämligen iris. Det innehåller fyra stycken kontinuerliga variabler som beskriver olika mått på blommor och ytterligare en kategorisk variabel som anger vilken art observationen tillhör. Datamaterialet ser ut som följer: Tabell 2.3: Första observationerna i Iris-data Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa ggpairs() kräver vissa argument för att kunna skapa ett diagram; data, anger vilket datamaterial som vi vill visualisera, columns, anger vilka kolumner ur datamaterialet som ska visualiseras, title, anger en titelrubrik för diagrammet, upper, anger vad vi vill att den övre diagonalen ska visa för information, diag, anger vad vi vill att diagonalen ska visa för information, lower, anger vad vi vill att den nedre diagonalen ska visa för information, axisLabels, anger inställningar för skalvärden i diagrammet. Notera att upper, diag, och lower måste ange sina argument i en list() där variabeltypen måste anges först. I detta exempel kommer vi behöva skriva list(continuous = ) då variablerna är kontinuerliga. Gå in i dokumentationen för funktionen och i Details står vilka andra diagram som kan visualiseras i de olika områdena. Nedanstående kod kommer skapa ett diagram innehållande spridningsdiagram i den nedre diagonalen över de fyra kontinuerliga variablerna som ligger på position 1:4 i datamaterialet iris. Vi väljer också här att plocka bort skalvärden på axlarna då syftet med dessa diagram är att visa sambandet mellan variabler och inte specifika värden som variablerna eller observationer förhåller sig till. Att vi tar bort skalvärden möjliggör också en större rityta som behövs om vi har ett flertal variabler som ska visualiseras. p &lt;- ggpairs(data = iris, columns = 1:4, title = &quot;Samband mellan mått på blommor&quot;, upper = list(continuous = &quot;points&quot;), diag = list(continuous = &quot;blankDiag&quot;), lower = list(continuous = &quot;blank&quot;), axisLabels = &quot;none&quot; ) p ## plot: [1,1] [=====&gt;------------------------------------------------------------------------------------------] 6% est: 0s ## plot: [1,2] [===========&gt;------------------------------------------------------------------------------------] 12% est: 0s ## plot: [1,3] [=================&gt;------------------------------------------------------------------------------] 19% est: 0s ## plot: [1,4] [=======================&gt;------------------------------------------------------------------------] 25% est: 0s ## plot: [2,1] [=============================&gt;------------------------------------------------------------------] 31% est: 0s ## plot: [2,2] [===================================&gt;------------------------------------------------------------] 38% est: 0s ## plot: [2,3] [=========================================&gt;------------------------------------------------------] 44% est: 0s ## plot: [2,4] [===============================================&gt;------------------------------------------------] 50% est: 0s ## plot: [3,1] [=====================================================&gt;------------------------------------------] 56% est: 0s ## plot: [3,2] [===========================================================&gt;------------------------------------] 62% est: 0s ## plot: [3,3] [=================================================================&gt;------------------------------] 69% est: 0s ## plot: [3,4] [=======================================================================&gt;------------------------] 75% est: 0s ## plot: [4,1] [=============================================================================&gt;------------------] 81% est: 0s ## plot: [4,2] [===================================================================================&gt;------------] 88% est: 0s ## plot: [4,3] [=========================================================================================&gt;------] 94% est: 0s ## plot: [4,4] [================================================================================================]100% est: 0s Som tur är finns det möjlighet att ändra vissa delar av diagrammet för att förtydliga vissa delar. p &lt;- p + theme_bw() + theme(plot.title = element_text(hjust = 0.5)) p ## plot: [1,1] [=====&gt;------------------------------------------------------------------------------------------] 6% est: 0s ## plot: [1,2] [===========&gt;------------------------------------------------------------------------------------] 12% est: 0s ## plot: [1,3] [=================&gt;------------------------------------------------------------------------------] 19% est: 0s ## plot: [1,4] [=======================&gt;------------------------------------------------------------------------] 25% est: 0s ## plot: [2,1] [=============================&gt;------------------------------------------------------------------] 31% est: 0s ## plot: [2,2] [===================================&gt;------------------------------------------------------------] 38% est: 0s ## plot: [2,3] [=========================================&gt;------------------------------------------------------] 44% est: 0s ## plot: [2,4] [===============================================&gt;------------------------------------------------] 50% est: 0s ## plot: [3,1] [=====================================================&gt;------------------------------------------] 56% est: 0s ## plot: [3,2] [===========================================================&gt;------------------------------------] 62% est: 0s ## plot: [3,3] [=================================================================&gt;------------------------------] 69% est: 0s ## plot: [3,4] [=======================================================================&gt;------------------------] 75% est: 0s ## plot: [4,1] [=============================================================================&gt;------------------] 81% est: 0s ## plot: [4,2] [===================================================================================&gt;------------] 88% est: 0s ## plot: [4,3] [=========================================================================================&gt;------] 94% est: 0s ## plot: [4,4] [================================================================================================]100% est: 0s 2.5.3.1 Färgläggning av observationer beroende på klass Det kan finnas tillfällen där samband mellan variabler ser olika ut beroende på en kategorisk variabel som inkluderas i datamaterialet. Detta kan också inkluderas i dessa diagram, men risken är att det blir för mycket information som trycks ihop på en för liten yta. Tyvärr finns inte ett enkelt sätt att ändra dessa färger eller skapa en legend som tydligt beskriver vilken färg som hör till vilken kategori ggpairs(data = iris, columns = 1:4, title = &quot;Samband mellan mått på blommor&quot;, upper = list(continuous = &quot;points&quot;), diag = list(continuous = &quot;blankDiag&quot;), lower = list(continuous = &quot;blank&quot;), axisLabels = &quot;none&quot;, mapping = aes(color = Species) ) + theme_bw() + theme(plot.title = element_text(hjust = 0.5)) ## plot: [1,1] [=====&gt;------------------------------------------------------------------------------------------] 6% est: 0s ## plot: [1,2] [===========&gt;------------------------------------------------------------------------------------] 12% est: 0s ## plot: [1,3] [=================&gt;------------------------------------------------------------------------------] 19% est: 0s ## plot: [1,4] [=======================&gt;------------------------------------------------------------------------] 25% est: 0s ## plot: [2,1] [=============================&gt;------------------------------------------------------------------] 31% est: 0s ## plot: [2,2] [===================================&gt;------------------------------------------------------------] 38% est: 0s ## plot: [2,3] [=========================================&gt;------------------------------------------------------] 44% est: 0s ## plot: [2,4] [===============================================&gt;------------------------------------------------] 50% est: 0s ## plot: [3,1] [=====================================================&gt;------------------------------------------] 56% est: 0s ## plot: [3,2] [===========================================================&gt;------------------------------------] 62% est: 0s ## plot: [3,3] [=================================================================&gt;------------------------------] 69% est: 0s ## plot: [3,4] [=======================================================================&gt;------------------------] 75% est: 0s ## plot: [4,1] [=============================================================================&gt;------------------] 81% est: 0s ## plot: [4,2] [===================================================================================&gt;------------] 88% est: 0s ## plot: [4,3] [=========================================================================================&gt;------] 94% est: 0s ## plot: [4,4] [================================================================================================]100% est: 0s "],["beskrivande-statistik.html", "3 Beskrivande statistik 3.1 Matematiska funktioner 3.2 Fördelningar", " 3 Beskrivande statistik Utifrån ett datamaterial innehållande många observationer kan man ibland behöva sammanfatta informationen för att kunna förmedla eller analysera materialet vidare. Här följer några grundläggande funktioner som finns i R som kan användas för att underlätta beräkningarna av dessa. 3.1 Matematiska funktioner Som tidigare exempel redan tagit upp i tidigare kapitel finns det redan skapade funktioner i R som kan utföra de matematiska beräkningar som vi behöver för beskrivande mått. mean() - beräknar medelvärdet av en variabel, sd() - beräknar standardavvikelsen av en variabel, var() - beräknar variansen av en variabel, sum() - beräknar summan av en variabel, length() - beräknar längden/antalet av en variabel, min() - anger det minsta värdet av en variabel, max() - anger det största värdet av en variabel, median() - beräknar medianen av en variabel, quantile() - beräknar angivna percentiler av en variabel. För att med quantile()-funktionen beräkna fram den första och tredje kvartilen måste argumentet probs = c(25, 75) anges tillsammans med variabeln som dessa ska beräknas från. Just för beskrivande statistik kan man istället för att enskilt beräkna alla ovanstående mått, använda funktionen summary(). Denna funktion anger minsta och största värde, första och tredje kvartilen, samt medelvärde och median. 3.2 Fördelningar Vi kan också vilja sammanfatta material i form av en fördelning, en förteckning över vilka värden och hur ofta de förekommer i variabeln. Tidigare kapitel har presenterat hur vi kan visualisera fördelningar i olika sorters diagram, stapeldiagram eller histogram, för olika sorters variabler, men vi kan också vilja använda någon av de generella fördelningarna för att beräkna sannolikheter eller andelar för en population. 3.2.1 Normalfördelningen Med R kommer vi kunna beräkna matematiskt (integrera) ytan under kurvan för olika värden istället för att vara begränsad till den standardiserade normalfördelningstabellen. Funktionerna som vi kommer vilja använda här är: 3.2.1.1 Beräkna sannolikheter från givna värden Funktionen pnorm() används för att beräkna andelar eller sannolikheter för givna utfall som vi är intresserade av. pnorm(q = 1.96, mean = 0, sd = 1, lower.tail = TRUE) ## [1] 0.9750021 I exemplet ovan anger vi att vi vill beräkna uttrycket \\(Pr(X \\le 1.96)\\) där \\(X \\sim N(\\mu = 0, \\sigma = 1)\\). Argumentet lower.tail som kan vara antingen TRUE eller FALSE anger vilket håll uttrycket ska beräknas. Om vi istället är intresserad av området till höger om \\(1.96\\), \\(Pr(X &gt; 1.96)\\) behöver vi ändra i funktionen till: pnorm(q = 1.96, mean = 0, sd = 1, lower.tail = FALSE) ## [1] 0.0249979 Här kan vi alltså ange vilken normalfördelning som helst genom att ändra värden på argumenten mean och sd. Det som vi måste hålla reda på är vilken sida av fördelningen som är av intresse och ange värdet för lower.tail utefter. Det är också med dessa funktioner som p-värden kan räknas ut. 3.2.1.2 Beräkna värden från givna sannolikheter Funktionen qnorm() används när vi vill beräkna värden (tabellvärden) utifrån givna sannolikheter. qnorm(p = 0.025, mean = 0, sd = 1, lower.tail = TRUE) ## [1] -1.959964 I ovan exempel beräknar vi vilket värde (\\(z\\)) från den standardiserade normalfördelningen som uppfyller uttrycket \\(Pr(Z\\le z) = 0.025\\). Om vi istället är intresserade av ytor på den högra sidan av fördelningen kan vi likt tidigare ange lower.tail = FALSE och då få ett uttryck likt \\(Pr(Z &gt; z) = 0.025\\) istället. Det är på detta sätt som tabellvärden beräknas fram till hypotesprövningar och intervallskattningar. Sannolikheten som vi är intresserade av blir då den angivna signifikansnivån. "],["statistisk-inferens.html", "4 Statistisk inferens 4.1 Inferens i en population 4.2 Inferens i två populationer 4.3 Jämförelse mellan fler än två grupper", " 4 Statistisk inferens För att kunna dra slutsatser om den målpopulation som vi önskar att undersöka utifrån den mindre grupp enheter som vi samlat in information om, måste vi utföra någon form av inferens. Detta kapitel kommer innehålla många olika metoder och är främst strukturerad kring hur många populationer vi vill utföra inferensen på och sedan med avseende på vilken parameter. 4.1 Inferens i en population När vi endast är intresserade av att undersöka en population (eller grupp). 4.1.1 Medelvärden, \\(\\mu\\) För inferens över medelvärden har vi följande krav som måste uppfyllas: Oberoende stickprov Kan uppfyllas genom att ett Obundet Slumpmässigt Urval (OSU) har skett Stickprovsmedelvärdet, \\(\\bar{X}\\), måste kunna anses vara normalfördelad Kan uppfyllas med hjälp av Centrala Gränsvärdessatsen (CGS) om stickprovet är nog stort, där tumregeln är \\(n &gt; 30\\). CGS säger att ett medelvärde (eller summa) av lika fördelade variabler kommer vara approximativt normalfördelad i detta fall. Om stickprovet är litet måste istället mätvariabeln, \\(X\\), som är av intresse anses vara normalfördelad. Detta innebär att den transformation som sker till medelvärdet också kommer vara normalfördelad. 4.1.1.1 Hypotesprövningar Vid en hypotesprövning av ett medelvärde utgår vi från den femstegsprocess som diskuterats under föreläsningarna. I följande exempel kommer vi titta på variabeln Sepal.Length från 2.3. När vi formulerar våra hypoteser gäller det att transformera vad det är vi vill undersöka till matematiska uttryck. Vi behöver också se till att vi använder rätt matematisk symbol i mothypotesen för att testet ska genomföras på rätt sätt. Till skillnad från i SPSS kan vi i R styra vilken sorts mothypotes som vi vill undersöka. Vi använder oss utav funktionen t.test() som har följande argument som är av intresse: x - anger vilken variabel som vi vill undersöka, alternative - anger vilken sorts mothypotes som ska testas där värdena \"two.sided\", \"less\" eller \"greater\", mu - anger det värde som vi vill testa, motsvarande \\(\\mu_0\\) i föreläsningarna, conf.level - anger konfidensgraden för testet, angivet i decimalform. Exempelvis skulle vi vara intresserade av att undersöka ifall genomsnittslängden av blommornas foderblad (Sepal.Length från iris-data) överstiger 5 cm. Vi ställer då upp hypoteser enligt: \\[\\begin{align} H_0: \\mu \\le 5 \\\\ H_a: \\mu &gt; 5 \\end{align}\\] Med en signifikansnivå på 5 procent blir funktionen som vi skriver i R som följer: t.test(x = iris$Sepal.Length, alternative = &quot;greater&quot;, mu = 5, conf.level = 0.95) ## ## One Sample t-test ## ## data: iris$Sepal.Length ## t = 12.473, df = 149, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean is greater than 5 ## 95 percent confidence interval: ## 5.731427 Inf ## sample estimates: ## mean of x ## 5.843333 I utskriften ser vi väldigt mycket information och, här ser vi en nackdel med R, att utskrifterna inte är tydligt strukturerade likt andra programvaror. Följande information kan utläsas ur de olika raderna: På första raden får vi information om vilken variabel som testet är gjort på. På andra raden får vi information från testet där t är den beräknade testvariabeln, df är frihetsgraderna i t-fördelningen, och p-value är p-värdet av testet. På tredje raden får vi information om vilken sorts mothypotes som har undersökts. På fjärde och femte raden fås ett beräknat konfidensintervall som skulle kunna användas för att besvara mothypotesen. I detta fall då vi har en mothypotes som är angiven som \\(&gt;\\), beräknas ett nedåt begränsat intervall. De sista raderna i utskriften anger beskrivande mått från stickprovet. För att kunna ta ett beslut från detta test kan vi direkt jämföra det beräknade p-värdet från utskriften med den angivna signifikansnivån. Om p-värdet är lägre kan vi förkasta \\(H_0\\), annars kan vi inte förkasta den. 4.1.1.2 Konfidensintervall För intervallskattningar för ett medelvärde kan samma funktion som för hypotesprövningar, t.test(), användas där argumentet alternative anger vilken sorts intervall som beräknas. Notera att vi för enkelsidiga intervall måste ange den mothypotes som stämmer överens med begränsningen. Ett tips för att bedöma detta är att titta på formuleringen som används i \\(H_a\\) och byta ut värdet som testas med den gräns som vi beräknar. Exempelvis skulle mothypotesen, mindre än 5 (\\(H_a: \\mu &lt; 5\\)), resultera i ett uppåt begränsat intervall enligt: \\[ \\mu &lt; \\bar{x} + t_{\\alpha(1); n-1} \\cdot \\frac{s}{\\sqrt{n}} \\] som med R-kod beräknas med: t.test(x = iris$Sepal.Length, alternative = &quot;less&quot;, conf.level = 0.95) ## ## One Sample t-test ## ## data: iris$Sepal.Length ## t = 86.425, df = 149, p-value = 1 ## alternative hypothesis: true mean is less than 0 ## 95 percent confidence interval: ## -Inf 5.95524 ## sample estimates: ## mean of x ## 5.843333 I utskriften är vi endast intresserade av det beräknade konfidensintervallet vilket innebär att vi inte behöver ange något värde på mu eftersom det endast påverkar beräkningen av \\(t_{test}\\). 4.2 Inferens i två populationer För detta kapitel kommer exemplen använda sig av det inbyggda materialet PlantGrowth. Materialet innehåller information om skörden, mätt i den torkade vikten av växten, uppdelad på tre olika grupper, en kontroll och två olika behandlingar. Vi kommer i detta kapitel endast fokusera på de observationer som hör till de olika behandlingarna men kommer titta närmare på alla tre grupper senare. Ett nytt datamaterial innehållande bara de två behandlingarna skapas och döps till TreatmentPlantGrowth Datamaterialet ser ut som följer: Tabell 4.1: Observerade skördar från växter med olika behandling weight group 4.81 trt1 4.17 trt1 4.41 trt1 3.59 trt1 5.87 trt1 3.83 trt1 6.03 trt1 4.89 trt1 4.32 trt1 4.69 trt1 6.31 trt2 5.12 trt2 5.54 trt2 5.50 trt2 5.37 trt2 5.29 trt2 4.92 trt2 6.15 trt2 5.80 trt2 5.26 trt2 4.2.1 Medelvärden, \\(\\mu\\) När vi vill jämföra medelvärden i två grupper behöver vi utöka de krav som gäller för metoderna: Oberoende inom vardera stickprov Kan uppfyllas genom att OSU har skett Oberoende mellan stickproven Om det har genomförts två separata OSU uppfylls detta Om grupperna inte anses påverka varandras mätvärden kan detta antas Stickprovsmedelvärdet, \\(\\bar{X}\\), måste kunna anses vara normalfördelad för båda grupperna Kan uppfyllas med hjälp av Centrala Gränsvärdessatsen (CGS) om stickprovet är nog stort, där tumregeln är \\(n &gt; 30\\). CGS säger att ett medelvärde (eller summa) av lika fördelade variabler kommer vara approximativt normalfördelad i detta fall. Om antalet i en grupp är litet måste istället mätvariabeln, \\(X\\), som är av intresse anses vara normalfördelad. Detta innebär att den transformation som sker till medelvärdet också kommer vara normalfördelad. 4.2.1.1 t.test() Likt för en population kommer funktionen t.test() användas för hypotesprövningar och konfidensintervall för jämförelser av två gruppers medelvärden. Vi lägger då till två ytterligare argument till dem som vi tidigare använt: y - anger den andra variabeln som vi vill jämföra med x, var.equal - anger om vi antar att variansen i de två grupperna anses lika (TRUE) eller ej (FALSE). I vårt exempeldata i 4.1 ser vi dock att vi har alla mätvärden i samma variabel, weight, och grupptillhörigheten i den andra variabeln, group. Detta innebär att vi måste ange variablerna på ett annat sätt i funktionen än x och y. Detta görs med två andra argument: formula - anger med formen mätvariabel ~ gruppvariabel hur mätvärden ska grupperas och testas, data - anger datamaterialet där variablerna finns. I följande kod testar vi huruvida medelvikten på skörden från de två behandlingarna skiljer sig åt. Notera att vi här gör ett antagande att vikten av en skörd antas vara normalfördelad då vi endast har 10 observationer från varje grupp och CGS kan inte tillämpas. Om vikten av en skörd är normalfördelad kommer också medelvärdet vara det. Vi gör också ett antagande om att variansen i mätvariabeln (vikt) hos de båda behandlingarna anses vara lika genom var.equal = TRUE. Detta antagande måste dock kunna motiveras. t.test(formula = weight ~ group, data = TreatmentPlantGrowth, alternative = &quot;two.sided&quot;, mu = 0, var.equal = TRUE, conf.level = 0.95) ## ## Two Sample t-test ## ## data: weight by group ## t = -3.0101, df = 18, p-value = 0.007518 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -1.4687336 -0.2612664 ## sample estimates: ## mean in group trt1 mean in group trt2 ## 4.661 5.526 När två grupper jämförs liknar utskriften mycket det som kom från ett enkelt t-test. Vi får samma information om testvariabel, frihetsgrader och p-värde, en indikation på vilket test det är som har utförts, och ett tillhörande konfidensintervall för skillnaden. 4.2.1.2 Parvisa observationer Om vi har samma enhet som mäts under två tidpunkter, eller om enheterna i de olika grupperna påverkar varandra på något sätt kommer inte kravet på oberoende mellan grupperna uppfyllas. I ett exempel (taget från http://www.sthda.com/english/wiki/paired-samples-t-test-in-r) mäts vikten av möss före och efter en okänd behandling. Materialet ser ut som följer: Tabell 4.2: Observerade vikter av möss före och efter en okänd behandling before after 200.1 392.9 190.9 393.2 192.7 345.1 213.0 393.0 241.4 434.0 196.9 427.9 172.2 422.0 185.5 383.9 205.2 392.3 193.7 352.2 För att kunna utföra en jämförelse av dessa två gruppernas medelvärden måste vi först beräkna en differens mellan varje parvisa observation och sedan genomföra inferens för en population med hypoteser som ändå stämmer överens med undersökningen eller frågeställningen som man vill besvara. Som tur är kan t.test() beräkna detta automatiskt genom att ange ett nytt argument paired = TRUE i funktionen. t.test(x = mice_data$before, y = mice_data$after, paired = TRUE) ## ## Paired t-test ## ## data: mice_data$before and mice_data$after ## t = -20.883, df = 9, p-value = 6.2e-09 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -215.5581 -173.4219 ## sample estimates: ## mean of the differences ## -194.49 I utskriften ändras egentligen bara titeln av utskriften gentemot utskriften från det föregående testet av oberoende grupper. Det är dock värt att notera att frihetsgraderna för testet beräknas korrekt utifrån att endast en grupp med differenser testas. Konfidensintervall finns också med i utskriften likt tidigare. 4.2.2 Icke-parametriska test Med biologiska data är det vanligt att endast ett fåtal observationer kan samlas in som innebär att inte Centrala Gränsvärdessatsen kan tillämpas för att uppfylla antagandet om en normalfördelad stickprovsstatistika. Vi kan i vissa fall inte heller motivera ett antagande om att mätvariabeln är normalfördelad och måste då frångå metoder som baserar sig på denna fördelning. 4.2.2.1 Mann-Whitney test Om vi vill jämföra två stycken oberoende grupper kan ett Mann-Whitney-test användas där det enda kravet som måste uppfyllas är just dem om oberoende stickprov. Notera att de kontrolleras på samma sätt som för tidigare tester. Lite missledande i R är att detta test kallas för wilcox.test(). Argumenten som används i denna funktion är: x - anger första variabeln, y - anger andra variabeln, alternative - anger vilken sorts mothypotes som ska undersökas, conf.level - anger konfidensgraden för testet exact - om ett exakt p-värde ska beräknas (det vill vi inte) correct - om kontinuitetskorrektion ska användas vid normalapproximeringen av p-värdet Vi kan också ange grupperna som ska jämföras med formula = mätvariabel ~ gruppvariabel och data = datamaterial likt exemplet nedan. wilcox.test(formula = weight ~ group, data = TreatmentPlantGrowth, alternative = &quot;two.sided&quot;, conf.level = 0.95, exact = FALSE, correct = FALSE) ## ## Wilcoxon rank sum test ## ## data: weight by group ## W = 16, p-value = 0.01017 ## alternative hypothesis: true location shift is not equal to 0 Utskriften för detta test är inte lika informationsrik som dem som vi sett tidigare, men det är fortfarande p-värdet som vi är intresserade för beslutsfattande. 4.2.2.2 Wilcoxon test Vid parvisa tester av två beroende grupper där kravet om en normalfördelad statistika inte uppfylls kan ett Wilcoxon test beräknas istället. I R använder vi samma funktion som innan men måste här ange argumentet paired = TRUE för att funktionen ska utföra korrekt test. wilcox.test(x = mice_data$before, y = mice_data$after, paired = TRUE, alternative = &quot;two.sided&quot;, conf.level = 0.95, exact = FALSE, correct = FALSE) ## ## Wilcoxon signed rank test ## ## data: mice_data$before and mice_data$after ## V = 0, p-value = 0.005062 ## alternative hypothesis: true location shift is not equal to 0 4.3 Jämförelse mellan fler än två grupper När vi vill jämföra fler än två grupper behöver vi använda oss utav andra metoder för att detta ska ske korrekt. Dessa metoder kallas för ANOVA som betyder ANalysis Of VAriance och tittar specifikt på skillnader i varianserna inom och mellan grupperna. Om en sådan jämförelse visar på att skillnader finns är det av intresse att identifiera mellan vilka specifika grupper som skillnader råder. Då fler än två grupper ska jämföras fungerar inte de tidigare metoderna utan vi måste nu titta på multipla jämförelser för att undersöka detta. Vi kommer även titta på fall där kravet om normalfördelning inte uppfylls och frågan måste besvaras med icke-parametriska metoder. Vi kan även tillämpa ANOVA vid tillfällen då vi har flera faktorer som vi anser påverka mätvariabeln. Vi behöver endast använda ett test som samtidigt kan testa för skillnader mellan olika nivåer av respektive faktor samt ifall faktorerna verkar interagera med varandra. 4.3.1 Envägs-ANOVA När vi vid tidigare metoder kontrollerade kraven som metoderna har var riskerna vid ett antagande om uppfyllda krav inte så stora. När vi ska använda oss av ANOVA-metoder måste följande krav vara uppfyllda, annars kommer slutsatserna som tas inte alls överensstämma med sanningen. Oberoende måste råda både inom gruppernas observationer och mellan grupperna. Mätvariabeln för alla grupper måste verka vara normalfördelad med lika varians. Dessa krav är dock svårt att bedöma och inom denna kurs avgränsar vi oss endast till att veta att dessa krav finns, men kontrollerar dem inte. Notera att det finns metoder som inte antar lika varians men dessa tas inte upp i denna kurs. 4.3.1.1 F-test Ett F-test är en form av hypotesprövning där fler än två medelvärden jämförs. Detta betyder att samma fem*stegsprocess som presenterats tidigare i kursen kan användas. Notera att steg 1 om antaganden inte kommer fokuseras på. Hypoteserna som testas måste här visa att vi dels undersöker medelvärden, samt att vi undersöker ifall det råder en skillnad mellan dessa \\(k\\) grupper. \\[\\begin{align*} H_0 &amp;: \\mu_1 = \\mu_2 = ... = \\mu_k \\\\ H_a &amp;: \\text{Minst två av } \\mu_i \\text{ i } H_0 \\text{ är olika} \\end{align*}\\] Alla värden som vi behöver för att kunna ta ett beslut om att förkasta eller inte förkasta den angivna \\(H_0\\) tar vi från en ANOVA-tabell. Funktionen som används i R för att skapa denna tabell är aov(). 4.3.1.1.1 Datastruktur Innan vi kan gå in på funktionen måste vi strukturera data på ett sätt som möjliggör analys. Vi kommer nu använda den struktur som vi har sett tidigare med en kolumn som indikerar på mätvariabelns värde för varje observation och en grupperingskolumn som anger vilken faktornivå som varje observation tillhör. Exempelvis kan data se ut som följer: Tabell 4.3: Urval av observerade antalet insekter som hittas på områden som behandlas med olika bekämpningsmedel (spray) count spray 20 A 14 A 16 B 14 B 5 D 5 D 3 E 3 E 5 E 15 F 4.3.1.2 aov() Funktionen har följande argument: formula - anger strukturen av modellen med strukturen mätvariabel ~ grupperingsvariabel, data - anger vilket datamaterial som ska analyseras. Om vi bara skulle köra funktionen likt vi har gjort vid tidigare metoder, kommer vi få en väldigt begränsad utskrift. Istället bör vi spara objektet som funktionen skapar till en ny variabel och använda andra funktioner för att hitta mer detaljerad information. I exemplet nedan sparas ANOVA-analysen i objektet anova_insect. anova_insect &lt;- aov(formula = count ~ spray, data = InsectSprays) För att få ut en ANOVA-tabell används funktionen summary(). Det är en funktion som sammanfattar olika objekt på olika sätt, och från aov() resulterar det i en ANOVA-tabell likt nedan. summary(anova_insect) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## spray 5 2669 533.8 34.7 &lt;2e-16 *** ## Residuals 66 1015 15.4 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Tabellen ser annorlunda ut jämfört med det som vi sett tidigare i SPSS, där den största skillnaden är att en rad för TOTAL saknas i R. Den är egentligen inte viktig då all information som behöver användas för F-testet finns ändå. I utskriften har vi frihetsgraderna (Df), kvadratsummorna SS (Sum Sq), medelkvadratsummorna MS (Mean Sq), F-testvariabeln (F-value) och p-värdet (Pr(&gt;F)). Notera att R använder sig av vetenskaplig notation vilket innebär att e motsvarar den matematiska beräkningen 10 upphöjt till. I tabellen ovan anges p-värdet som &lt;2e-16 vilket egentligen blir \\(2\\cdot 10^{\\text{-}16} = 0.0000000000000002\\). 4.3.1.3 Multipla jämförelser Om vi i F-testet kan förkasta \\(H_0\\) till förmån för mothypotesen vet vi att det finns en skillnad mellan minst två medelvärden, men inte vilka. Det är nu intressant att göra jämförelser för att bedöma mellan vilka av de \\(k\\) grupper, medelvärdena skiljer sig åt. Denna bedömning görs med metoder som kallas multipla jämförelser som parvist jämför alla grupper med en sammanlagd konfidensgrad. Dessa jämförelser beräknas i R med ett nytt paket, nämligen multcomp. Glöm inte att installera paketet genom install.packages(\"multcomp\") och ladda in paketet genom require(multcomp). 4.3.1.4 Tukey-test Om vi är intresserade av att jämföra alla grupper i vår faktor (även kallad alla faktornivåer) bör vi beräkna Tukey-test. Funktionen för dessa beräkningar i R är TukeyHSD(). Det enda argument som behöver anges är x där vi anger det ANOVA-objekt som skapades innan. Vi kan också ändra familje-konfidensen (alltså den konfidensgrad som sammanlagt gäller) med argumentet conf.level. TukeyHSD(x = anova_insect) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = count ~ spray, data = InsectSprays) ## ## $spray ## diff lwr upr p adj ## B-A 0.8333333 -3.866075 5.532742 0.9951810 ## C-A -12.4166667 -17.116075 -7.717258 0.0000000 ## D-A -9.5833333 -14.282742 -4.883925 0.0000014 ## E-A -11.0000000 -15.699409 -6.300591 0.0000000 ## F-A 2.1666667 -2.532742 6.866075 0.7542147 ## C-B -13.2500000 -17.949409 -8.550591 0.0000000 ## D-B -10.4166667 -15.116075 -5.717258 0.0000002 ## E-B -11.8333333 -16.532742 -7.133925 0.0000000 ## F-B 1.3333333 -3.366075 6.032742 0.9603075 ## D-C 2.8333333 -1.866075 7.532742 0.4920707 ## E-C 1.4166667 -3.282742 6.116075 0.9488669 ## F-C 14.5833333 9.883925 19.282742 0.0000000 ## E-D -1.4166667 -6.116075 3.282742 0.9488669 ## F-D 11.7500000 7.050591 16.449409 0.0000000 ## F-E 13.1666667 8.467258 17.866075 0.0000000 Utskriften visar alla jämförelser i kolumnen längst till vänster och de efterföljande kolumnerna innehåller differensen i stickprovet, beräknade konfidensintervall, samt p-värdet för testet. 4.3.1.5 Dunnett-test Om vi har en kontrollgrupp som en av grupperna och vi har ett intresse av att endast jämföra alla andra grupper med denna kontrollgrupp bör vi beräkna Dunnett-test. Funktionen för detta test, glht(), är lite rörig så vi delar upp den i två steg. Funktionen kräver två argument: model - anger det ANOVA-objekt som beräknats sedan tidigare, linfct - anger vilken typ utav funktion (jämförelse) som ska beräknas. I linfct behöver vi ange mcp(grupperingsvariabeln = \"Dunnett\") där mcp står för multiple comparison. För att få information som kan användas för att bedöma ifall jämförelsen är signifikant måste vi använda summary() på objektet som skapas från denna funktion och det kan göras med hjälp av %&gt;% (som ett alternativ till det vi gjorde med aov()). Notera att kontrollgruppen antas vara den första gruppen som finns i materialet. För att ändra denna ordning kan funktionen relevel(x = grupperingsvariabel, ref = \"kontrollgrupp\") användas. glht(model = anova_insect, linfct = mcp(spray = &quot;Dunnett&quot;)) %&gt;% summary() ## ## Simultaneous Tests for General Linear Hypotheses ## ## Multiple Comparisons of Means: Dunnett Contrasts ## ## ## Fit: aov(formula = count ~ spray, data = InsectSprays) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## B - A == 0 0.8333 1.6011 0.520 0.979 ## C - A == 0 -12.4167 1.6011 -7.755 &lt;1e-04 *** ## D - A == 0 -9.5833 1.6011 -5.985 &lt;1e-04 *** ## E - A == 0 -11.0000 1.6011 -6.870 &lt;1e-04 *** ## F - A == 0 2.1667 1.6011 1.353 0.526 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## (Adjusted p values reported -- single-step method) Utkskriften innehåller i kolumnerna (från vänster till höger) vilka grupper som jämförs, skillnaden i mätvärden, medelfelet, testvariabeln, och till sist p-värdet. 4.3.2 Icke-parametrisk metod Om vi inte kan anta att materialet är normalfördelad kan vi istället för ett F-test beräkna ett icke-parametriskt test, som vi kallar för Kruskal-Wallis-test. Hypoteserna benämner vi med ord, inte någon parameter, och de kan se ut som följer: \\[\\begin{align*} H_0 &amp;: \\text{Det finns inga skillnader mellan grupperna} \\\\ H_a &amp;: \\text{Det finns skillnader mellan grupperna} \\end{align*}\\] Funktionen som används för detta test är kruskal.test() och argumenten är samma som vi använde för F-testet tidigare, formula och data. kruskal.test(formula = count ~ spray, data = InsectSprays) ## ## Kruskal-Wallis rank sum test ## ## data: count by spray ## Kruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10 Från utskriften kan vi läsa ut ett p-värde (p-value) som sedan kan jämföras med signifikansnivån och ta ett beslut. 4.3.3 Tvåvägs-ANOVA anova_model &lt;- aov(formula = len ~ supp * dose, data = ToothGrowth) summary(anova_model) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## supp 1 205.4 205.4 12.317 0.000894 *** ## dose 1 2224.3 2224.3 133.415 &lt; 2e-16 *** ## supp:dose 1 88.9 88.9 5.333 0.024631 * ## Residuals 56 933.6 16.7 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 "]]
